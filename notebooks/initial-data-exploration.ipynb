{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze texture features\n",
    "texture_features = np.vstack(sample_df['texture_features'].values)\n",
    "texture_df = pd.DataFrame(texture_features, columns=[f'texture_{i}' for i in range(texture_features.shape[1])])\n",
    "texture_df['class'] = sample_df['class'].values\n",
    "\n",
    "# Plot first two texture features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='texture_0', y='texture_1', hue='class', data=texture_df)\n",
    "plt.title('Texture Features by Class (First Two Haralick Features)')\n",
    "plt.xlabel('Texture Feature 1')\n",
    "plt.ylabel('Texture Feature 2')\n",
    "plt.legend(title='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot of texture features shows some separation between classes, indicating that texture is an important characteristic for distinguishing different types of skin lesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Combine all features for dimensionality reduction\n",
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Combine all features\n",
    "combined_features = np.hstack([\n",
    "    StandardScaler().fit_transform(np.vstack(sample_df['color_hist'].values)),\n",
    "    StandardScaler().fit_transform(np.vstack(sample_df['shape_features'].values)),\n",
    "    StandardScaler().fit_transform(np.vstack(sample_df['texture_features'].values))\n",
    "])\n",
    "\n",
    "# Apply PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(combined_features)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['class'] = sample_df['class'].values\n",
    "pca_df['class_name'] = pca_df['class'].map(CLASS_NAMES)\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='class_name', data=pca_df, palette='tab10', s=100, alpha=0.7)\n",
    "plt.title('PCA of Combined Features by Class')\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.legend(title='Class', loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Apply t-SNE for more complex visualization\n",
    "tsne = TSNE(n_components=2, perplexity=min(30, len(sample_df) - 1), random_state=42)\n",
    "tsne_result = tsne.fit_transform(combined_features)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "tsne_df = pd.DataFrame(data=tsne_result, columns=['t-SNE1', 't-SNE2'])\n",
    "tsne_df['class'] = sample_df['class'].values\n",
    "tsne_df['class_name'] = tsne_df['class'].map(CLASS_NAMES)\n",
    "\n",
    "# Plot t-SNE results\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='t-SNE1', y='t-SNE2', hue='class_name', data=tsne_df, palette='tab10', s=100, alpha=0.7)\n",
    "plt.title('t-SNE of Combined Features by Class')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(title='Class', loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the PCA and t-SNE visualizations show that the combined features (color, shape, and texture) provide reasonable separation between the classes, although there is still considerable overlap. This suggests that these features are informative but not sufficient for perfect classification, highlighting the need for more sophisticated approaches like deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze image complexity\n",
    "# Calculate complexity based on edge detection\n",
    "def calculate_image_complexity(img_path):\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    complexity = np.sum(edges > 0) / (img.shape[0] * img.shape[1])\n",
    "    return complexity\n",
    "\n",
    "# Get complexity for a sample of images\n",
    "complexity_data = []\n",
    "\n",
    "for class_name in CLASS_NAMES.keys():\n",
    "    class_samples = metadata[metadata['dx'] == class_name].sample(\n",
    "        min(sample_size, sum(metadata['dx'] == class_name)), random_state=42\n",
    "    )\n",
    "    \n",
    "    for _, row in class_samples.iterrows():\n",
    "        img_id = row['image_id']\n",
    "        \n",
    "        # Find image file\n",
    "        img_path = None\n",
    "        for img_dir in [IMAGE_DIR_PART1, IMAGE_DIR_PART2]:\n",
    "            temp_path = img_dir / f\"{img_id}.jpg\"\n",
    "            if temp_path.exists():\n",
    "                img_path = temp_path\n",
    "                break\n",
    "        \n",
    "        if img_path is None:\n",
    "            continue\n",
    "        \n",
    "        complexity = calculate_image_complexity(img_path)\n",
    "        \n",
    "        complexity_data.append({\n",
    "            'image_id': img_id,\n",
    "            'class': class_name,\n",
    "            'class_name': CLASS_NAMES[class_name],\n",
    "            'complexity': complexity\n",
    "        })\n",
    "\n",
    "complexity_df = pd.DataFrame(complexity_data)\n",
    "\n",
    "# Plot complexity by class\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='class_name', y='complexity', data=complexity_df)\n",
    "plt.title('Image Complexity by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Complexity Score (Edge Density)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot complexity distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=complexity_df, x='complexity', hue='class_name', kde=True, bins=20)\n",
    "plt.title('Complexity Distribution by Class')\n",
    "plt.xlabel('Complexity Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity analysis reveals that different skin lesion classes have varying levels of complexity in terms of edge patterns. This information could be useful for preprocessing strategies and model architecture design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesion Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a function to calculate the lesion size based on segmentation\n",
    "def calculate_lesion_size(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Get the largest contour (assumed to be the lesion)\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        lesion_area = cv2.contourArea(largest_contour)\n",
    "        total_area = img.shape[0] * img.shape[1]\n",
    "        lesion_size_ratio = lesion_area / total_area\n",
    "        return lesion_size_ratio\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Get lesion size for a sample of images\n",
    "lesion_size_data = []\n",
    "\n",
    "for class_name in CLASS_NAMES.keys():\n",
    "    class_samples = metadata[metadata['dx'] == class_name].sample(\n",
    "        min(sample_size, sum(metadata['dx'] == class_name)), random_state=42\n",
    "    )\n",
    "    \n",
    "    for _, row in class_samples.iterrows():\n",
    "        img_id = row['image_id']\n",
    "        \n",
    "        # Find image file\n",
    "        img_path = None\n",
    "        for img_dir in [IMAGE_DIR_PART1, IMAGE_DIR_PART2]:\n",
    "            temp_path = img_dir / f\"{img_id}.jpg\"\n",
    "            if temp_path.exists():\n",
    "                img_path = temp_path\n",
    "                break\n",
    "        \n",
    "        if img_path is None:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            lesion_size = calculate_lesion_size(img_path)\n",
    "            \n",
    "            lesion_size_data.append({\n",
    "                'image_id': img_id,\n",
    "                'class': class_name,\n",
    "                'class_name': CLASS_NAMES[class_name],\n",
    "                'lesion_size': lesion_size\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_id}: {e}\")\n",
    "\n",
    "lesion_size_df = pd.DataFrame(lesion_size_data)\n",
    "\n",
    "# Plot lesion size by class\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='class_name', y='lesion_size', data=lesion_size_df)\n",
    "plt.title('Lesion Size by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Lesion Size Ratio (Area/Total)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot lesion size distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=lesion_size_df, x='lesion_size', hue='class_name', kde=True, bins=20)\n",
    "plt.title('Lesion Size Distribution by Class')\n",
    "plt.xlabel('Lesion Size Ratio')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lesion size analysis shows variations across different classes, which could be an important factor in classification. This might inform our approach to preprocessing and model design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Combine complexity and lesion size analysis\n",
    "combined_analysis = pd.merge(\n",
    "    complexity_df[['image_id', 'class', 'class_name', 'complexity']],\n",
    "    lesion_size_df[['image_id', 'lesion_size']],\n",
    "    on='image_id'\n",
    ")\n",
    "\n",
    "# Plot complexity vs lesion size\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='complexity', y='lesion_size', hue='class_name', data=combined_analysis, s=100, alpha=0.7)\n",
    "plt.title('Complexity vs Lesion Size by Class')\n",
    "plt.xlabel('Complexity Score')\n",
    "plt.ylabel('Lesion Size Ratio')\n",
    "plt.legend(title='Class')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate correlation between complexity and lesion size\n",
    "complexity_lesion_corr = combined_analysis['complexity'].corr(combined_analysis['lesion_size'])\n",
    "print(f\"Correlation between complexity and lesion size: {complexity_lesion_corr:.4f}\")\n",
    "\n",
    "# ANOVA test for complexity differences between classes\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "classes = []\n",
    "for cls in complexity_df['class'].unique():\n",
    "    classes.append(complexity_df[complexity_df['class'] == cls]['complexity'].values)\n",
    "\n",
    "f_stat, p_value = f_oneway(*classes)\n",
    "print(f\"\\nANOVA test for complexity differences between classes:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference in complexity between classes.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference in complexity between classes.\")\n",
    "\n",
    "# ANOVA test for lesion size differences between classes\n",
    "lesion_classes = []\n",
    "for cls in lesion_size_df['class'].unique():\n",
    "    lesion_classes.append(lesion_size_df[lesion_size_df['class'] == cls]['lesion_size'].values)\n",
    "\n",
    "f_stat, p_value = f_oneway(*lesion_classes)\n",
    "print(f\"\\nANOVA test for lesion size differences between classes:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference in lesion size between classes.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference in lesion size between classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our exploratory data analysis of the HAM10000 dataset, we can summarize the following key findings:\n",
    "\n",
    "1. **Class Distribution:**\n",
    "   - The dataset is highly imbalanced, with 'Melanocytic Nevi' (nv) being the dominant class (6705 images, 66.9%).\n",
    "   - 'Dermatofibroma' (df) has the fewest samples (115 images, 1.1%), which may require special handling during modeling.\n",
    "\n",
    "2. **Demographic Patterns:**\n",
    "   - Skin lesions have age-related distributions, with some types (like Actinic Keratoses) more common in older populations.\n",
    "   - Gender distributions vary by lesion type, which could be useful information for the model.\n",
    "\n",
    "3. **Localization Patterns:**\n",
    "   - Different skin lesion types have different body location preferences.\n",
    "   - Melanoma is more common on sun-exposed areas like the back and trunk.\n",
    "\n",
    "4. **Image Properties:**\n",
    "   - Most images have similar dimensions but varying aspect ratios.\n",
    "   - Color distributions show some class-specific patterns.\n",
    "   - Shape and texture features show promise for distinguishing between classes.\n",
    "\n",
    "5. **Feature Analysis:**\n",
    "   - PCA and t-SNE visualizations suggest that the combined features provide good class separation.\n",
    "   - There are significant differences in image complexity and lesion size between classes.\n",
    "\n",
    "6. **Challenges for Modeling:**\n",
    "   - Class imbalance will require techniques like class weighting or data augmentation.\n",
    "   - Visual similarity between some classes (e.g., melanoma and nevi) makes classification challenging.\n",
    "   - Variations in image quality, lesion size, and complexity must be addressed in preprocessing.\n",
    "\n",
    "7. **Next Steps:**\n",
    "   - Implement data augmentation to address class imbalance.\n",
    "   - Design a CNN architecture that can capture the subtle differences between classes.\n",
    "   - Consider using feature extraction for color, shape, and texture as complementary inputs.\n",
    "   - Implement explainable AI techniques to understand model decisions.\n",
    "\n",
    "These findings will guide our approach to implementing the CNN model described in the paper \"Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\"."
   ]
  }
]
