{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI for Skin Cancer Detection\n",
    "\n",
    "This notebook demonstrates how to use the explainability methods in the XAI package to understand the predictions of skin lesion classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Add the project directory to the path\n",
    "# This assumes the notebook is in the notebooks/ directory\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "# Import project modules\n",
    "from XAI.config import MODELS_DIR, FIGURES_DIR, CLASS_NAMES, MODEL_INPUT_SIZE\n",
    "from XAI.dataset import get_transforms\n",
    "from XAI.modeling.ResizeLayer import ResizedModel\n",
    "from XAI.modeling.AllModels import dl_models, device\n",
    "from XAI.modeling.train import load_best_model\n",
    "from XAI.explainers import LimeExplainer, ShapExplainer, GradCamExplainer\n",
    "\n",
    "# Set up matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a Trained Model\n",
    "\n",
    "First, we'll load one of our trained models. You can choose a different model by changing the `model_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model to explain (0 for SkinLesionCNN, 2 for CustomCNN, etc.)\n",
    "model_idx = 0\n",
    "\n",
    "# Get model class\n",
    "model_class = dl_models[model_idx]\n",
    "model_name = model_class.name()\n",
    "print(f\"Using model: {model_name}\")\n",
    "\n",
    "# Create model with proper input size\n",
    "model = ResizedModel(model_class.inputSize(), model_class()).to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_model_path, checkpoint = load_best_model(model_name)\n",
    "\n",
    "if checkpoint is not None:\n",
    "    # Load model weights\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"Loaded model from {best_model_path}\")\n",
    "else:\n",
    "    print(f\"No saved model found for {model_name}, using untrained model\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess an Image\n",
    "\n",
    "Now, let's load a sample image to explain. You can replace this with any skin lesion image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your sample image\n",
    "# You can use a sample from the HAM10000 dataset in data/interim/organized_by_class/\n",
    "image_path = \"../data/interim/organized_by_class/mel/ISIC_0024306.jpg\"  # Example melanoma image\n",
    "\n",
    "# Load image\n",
    "image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Sample Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Preprocess the image\n",
    "transform = get_transforms(\"val\")\n",
    "image_tensor = transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a Prediction\n",
    "\n",
    "Let's get the model's prediction for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch dimension and move to device\n",
    "batch_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "# Get class name\n",
    "class_keys = list(CLASS_NAMES.keys())\n",
    "class_name = CLASS_NAMES[class_keys[predicted_class]]\n",
    "print(f\"Predicted class: {class_name} (index: {predicted_class})\")\n",
    "\n",
    "# Plot probabilities\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(CLASS_NAMES)), probabilities.cpu().numpy())\n",
    "plt.xlabel(\"Class Index\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Class Probabilities\")\n",
    "plt.xticks(range(len(CLASS_NAMES)), [CLASS_NAMES[cls] for cls in class_keys], rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explain the Prediction with LIME\n",
    "\n",
    "Now, let's use LIME to explain why the model made this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function for LIME\n",
    "def preprocess_fn(img):\n",
    "    return transform(img)\n",
    "\n",
    "# Initialize LIME explainer\n",
    "lime_explainer = LimeExplainer(model, device, CLASS_NAMES, preprocess_fn)\n",
    "\n",
    "# Generate explanation\n",
    "print(\"Generating LIME explanation (this may take a minute)...\")\n",
    "lime_exp = lime_explainer.explain(image, num_samples=500)  # Reduce samples for speed in notebook\n",
    "\n",
    "# Visualize explanation\n",
    "lime_fig, _ = lime_explainer.visualize(lime_exp, image, label=predicted_class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explain the Prediction with SHAP\n",
    "\n",
    "Next, let's use SHAP to provide another explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "shap_explainer = ShapExplainer(model, device, CLASS_NAMES, preprocess_fn)\n",
    "\n",
    "# Generate explanation (use a small number of samples for speed in notebook)\n",
    "print(\"Generating SHAP explanation (this may take a minute)...\")\n",
    "shap_values = shap_explainer.explain(image, n_samples=25)  # Use a small number for speed\n",
    "\n",
    "# Visualize explanation\n",
    "shap_fig, _ = shap_explainer.visualize(shap_values, image, label=predicted_class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explain the Prediction with GradCAM\n",
    "\n",
    "Finally, let's use GradCAM to highlight the regions of the image that influenced the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradCAM explainer\n",
    "try:\n",
    "    gradcam_explainer = GradCamExplainer(model)\n",
    "    \n",
    "    # Generate explanation\n",
    "    print(\"Generating GradCAM explanation...\")\n",
    "    gradcam_heatmap = gradcam_explainer.explain(batch_tensor)\n",
    "    \n",
    "    # Convert image to [0, 1] range for visualization\n",
    "    normalized_image = image.astype(float) / 255\n",
    "    \n",
    "    # Visualize\n",
    "    cam_image = gradcam_explainer.visualize(gradcam_heatmap, normalized_image, class_name=class_name)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error generating GradCAM explanation: {e}\")\n",
    "    print(\"This may happen if the model architecture is not compatible with GradCAM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison of Explanations\n",
    "\n",
    "Let's compare all the explanations side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for all explanations\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Original\\nPrediction: {class_name}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# LIME explanation\n",
    "plt.subplot(1, 4, 2)\n",
    "temp, mask = lime_exp.get_image_and_mask(\n",
    "    predicted_class, \n",
    "    positive_only=True, \n",
    "    num_features=5, \n",
    "    hide_rest=False\n",
    ")\n",
    "plt.imshow(mark_boundaries(temp, mask))\n",
    "plt.title(\"LIME Explanation\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# SHAP explanation\n",
    "plt.subplot(1, 4, 3)\n",
    "# For visualization, sum absolute SHAP values across channels\n",
    "shap_combined = np.abs(shap_values[predicted_class][0]).sum(axis=0)\n",
    "# Normalize to [0, 1] for visualization\n",
    "shap_normalized = shap_combined / shap_combined.max()\n",
    "plt.imshow(shap_normalized, cmap='hot')\n",
    "plt.title(\"SHAP Values\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# GradCAM explanation\n",
    "try:\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(cam_image)\n",
    "    plt.title(\"GradCAM Heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use three different explainability methods to understand the predictions of our skin lesion classification model:\n",
    "\n",
    "1. **LIME**: Shows which regions of the image support or contradict the prediction.\n",
    "2. **SHAP**: Assigns importance values to each pixel based on cooperative game theory.\n",
    "3. **GradCAM**: Highlights areas of the image that activate specific features in the network.\n",
    "\n",
    "These explanations provide complementary views of the model's decision-making process, which is crucial for building trust in the model, especially in medical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
